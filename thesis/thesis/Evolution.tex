\chapter{Packing Rules Evolution}

This chapter introduces evolutionary algorithms as a method
to improve the quality of packing solutions.
The main idea is to evolve a population of candidate solutions,
called individuals, over a number of iterations,
using principles inspired by natural evolution.

The evolutionary process evaluates the fitness of each individual,
selects the more promising solutions according to their fitness,
and applies variation operators to generate new candidate solutions.
Through repeated iterations, the population is gradually refined,
searching for high-quality individuals that lead to more efficient solutions.

In the context of the packing problem, each individual
represents the packing rules in its vector form,
defining a distinct way to generate a deterministic packing solution.

\section{Hill Climbing}

Hill Climbing is the simplest of the evolutionary algorithms.
For each individual, a child is generated by applying small mutations according to a predefined mutation probability.
After evaluating the child’s fitness, either the parent or the child is selected for the next iteration based on which has higher fitness.

This approach works because each individual explores a small neighborhood in the solution space, but since the population contains many individuals, the overall search covers a much larger region.
In other words, while each hill climbing step is local, the collective exploration by the population allows the algorithm to find high-quality individuals efficiently.

In this work, mutation is applied by independently replacing each element of the packing-rules vector with a random value sampled uniformly from the interval~[0,1] according to a predefined mutation probability.
This alters box order, rotations, or heuristic preferences, producing a modified candidate solution that is evaluated against its parent.

\begin{itemize}
    \item \textbf{Mutation probability} — the probability that element in the vector will be replaced with a random value in the interval [0,1].
    \item \textbf{Population size} — the number of individuals that undergo independent Hill Climbing.
    \item \textbf{Number of generations} — total number of Hill Climbing iterations applied to each individual.
\end{itemize}

\section{Simulated Annealing}

Simulated Annealing is similar to Hill Climbing in that it iteratively 
generates a new candidate solution from a current solution, 
typically by applying small mutations to the individual’s vector representation. 
The key difference is that SA can accept worse solutions with a probability that depends on a temperature parameter, which gradually decreases over time.

The temperature controls the likelihood that a child solution will replace its parent even 
if it has lower fitness. Early in the search, when the temperature is high, 
worse solutions are more likely to be accepted, promoting exploration of 
the solution space. As the temperature decreases, the acceptance probability 
of worse solutions declines, making the algorithm behave more like Hill Climbing and focus on local improvements.

The temperature is decreased each generation according to a geometric cooling schedule:
\[
T_{next} = \alpha \cdot T_{current},
\]
where \(\alpha \in (0,1)\) is the cooling rate. 
Early iterations allow greater exploration, while later iterations focus on local refinement.

\begin{itemize}
    \item \textbf{Initial temperature} — the starting value of the temperature controlling the acceptance probability of worse solutions.
    \item \textbf{Cooling rate} — the factor by which the temperature decreases each iteration.
    \item \textbf{Mutation probability} — the probability that an element in the vector will be replaced with a random value in the interval [0,1].
    \item \textbf{Population size} — the number of individuals that undergo independent Simulated Annealing.
    \item \textbf{Number of generations} — total number of iterations applied to each individual.
\end{itemize}
 

\section{Elitist Genetic Algorithm}

The Elitist Genetic Algorithm evolves a population of individuals
by combining and modifying existing solutions while giving special treatment to the best-performing individuals. \cite{goncalves2013} 

A subset of the population, called the \emph{elite}, consists of the individuals with the highest fitness. 
Elite solutions are preserved across generations and updated after each generation to ensure that the best traits are not lost.

New individuals are generated using a combination of selection, crossover, and mutation. 
One parent is selected from the elite subset, while the other is chosen from the remainder 
of the population. For each element of the offspring vector, 
a value is inherited from one of the parents according to a predefined probability, 
typically giving a higher chance to inherit from the elite parent. 
This allows beneficial traits from the elite to propagate while maintaining diversity.

After crossover, mutation is applied. This introduces additional variation, 
potentially altering box order, rotations, or heuristic preferences.

Additionally, a small number of entirely random solutions are introduced into the population each generation. 
These individuals further increase diversity and help prevent premature convergence to local optima.

The newly generated solutions replace part of the non-elite population, while the elite remain unchanged.

In this work, mutation is applied by independently replacing each element of the packing-rules vector with a 
random value sampled uniformly from the interval [0,1], according to the mutation probability parameter.

For each crossover, one parent is selected from the elite subset using tournament selection 
with the tournament size given by a parameter, and the other parent is selected randomly from the non-elite subset

\begin{itemize}
    \item \textbf{Population size} — total number of candidate solutions in the population.
    \item \textbf{Elite size} — number of top-performing individuals preserved each generation.
    \item \textbf{Mutation probability} — probability that an element in the packing-rules vector will be replaced with a random value.
    \item \textbf{Crossover bias} — probability of inheriting an element from the elite parent during uniform crossover.
    \item \textbf{Tournament size} — number of elite candidates considered when selecting a parent via tournament selection.
    \item \textbf{Number of generations} — total number of iterations the algorithm runs.
    \item \textbf{Number of random individuals} — number of entirely new solutions introduced into the population each generation.
\end{itemize}

\section{Memetic Extension of the Elitist Genetic Algorithm}

The Memetic Elitist Genetic Algorithm extends the Elitist Genetic Algorithm by applying a local search to newly generated packing rules.
After crossover and mutation, each offspring undergoes a short Hill Climbing procedure, refining the solution in its local neighborhood.
This combines the global search capability of the genetic algorithm with the ability of local search, often resulting in faster convergence and higher-quality solutions.

The extent of the local search is controlled by a parameter specifying the number of Hill Climbing iterations applied to each offspring.
In this implementation, Hill Climbing is executed for the given number of iterations, producing several candidate solutions. 
The best among these candidates is selected. If none of the candidates improves over the original offspring, the original solution is retained.
This allows balancing between computational cost and solution refinement. A higher number of iterations may improve the solution quality but increases 
runtime, while a smaller number keeps the process faster but explores less of the local neighborhood.

\begin{itemize}
    \item \textbf{Number of Hill Climbing iterations} — number of independent Hill Climbing runs performed per offspring; the best result is chosen or the original solution is kept if none is better.
    \item \textbf{Hill Climbing mutation probability} — probability that an element in the packing-rules vector is mutated during the memetic Hill Climbing step.
\end{itemize}